{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13452811,"sourceType":"datasetVersion","datasetId":8539258}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"75c92404","cell_type":"code","source":"import os\nimport pandas as pd\nimport seaborn as sns\nimport cv2\nimport numpy as np \nfrom PIL import Image\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom skimage import io, color\nfrom skimage.feature import hog\nfrom joblib import Parallel, delayed\nimport numpy as np\nfrom skimage.transform import resize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T13:19:35.174623Z","iopub.execute_input":"2025-10-21T13:19:35.175700Z","iopub.status.idle":"2025-10-21T13:19:35.229252Z","shell.execute_reply.started":"2025-10-21T13:19:35.175663Z","shell.execute_reply":"2025-10-21T13:19:35.228139Z"}},"outputs":[],"execution_count":23},{"id":"7f00d181","cell_type":"code","source":"\n\nimages_dir = '/kaggle/input/nhapmoncv/data/images'\n\nclasses = [d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))]\n\nlabel_map = {cls: idx for idx, cls in enumerate(classes)}\n\ndata = []\nfor cls in classes:\n    cls_folder = os.path.join(images_dir, cls)\n    for fname in os.listdir(cls_folder):\n        if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n            file_path = os.path.join(cls_folder, fname)\n            label = label_map[cls]\n            data.append((file_path, label))\n\nclasses = [d.split(\"-\")[-1] for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))]\n\nlabel_map = {cls: idx for idx, cls in enumerate(classes)}\n\n\ndf = pd.DataFrame(data, columns=['filepath', 'label'])\nprint(df.head())\nprint(\"Number of images:\", len(df))\nprint(\"Number of classes:\", len(classes))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:32:55.203997Z","iopub.execute_input":"2025-10-21T10:32:55.204808Z","iopub.status.idle":"2025-10-21T10:32:59.054896Z","shell.execute_reply.started":"2025-10-21T10:32:55.204780Z","shell.execute_reply":"2025-10-21T10:32:59.053939Z"}},"outputs":[{"name":"stdout","text":"                                            filepath  label\n0  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\n1  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\n2  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\n3  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\n4  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\nNumber of images: 20580\nNumber of classes: 120\n","output_type":"stream"}],"execution_count":3},{"id":"9036a410","cell_type":"code","source":"label_map = {v:k for k,v in label_map.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:32:59.055829Z","iopub.execute_input":"2025-10-21T10:32:59.056109Z","iopub.status.idle":"2025-10-21T10:32:59.060428Z","shell.execute_reply.started":"2025-10-21T10:32:59.056080Z","shell.execute_reply":"2025-10-21T10:32:59.059546Z"}},"outputs":[],"execution_count":4},{"id":"7e9744f9","cell_type":"code","source":"df[\"breed\"] = df[\"label\"].map(label_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:32:59.062050Z","iopub.execute_input":"2025-10-21T10:32:59.062293Z","iopub.status.idle":"2025-10-21T10:32:59.081567Z","shell.execute_reply.started":"2025-10-21T10:32:59.062273Z","shell.execute_reply":"2025-10-21T10:32:59.080668Z"}},"outputs":[],"execution_count":5},{"id":"9968eec8","cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:32:59.082446Z","iopub.execute_input":"2025-10-21T10:32:59.082737Z","iopub.status.idle":"2025-10-21T10:32:59.108708Z","shell.execute_reply.started":"2025-10-21T10:32:59.082717Z","shell.execute_reply":"2025-10-21T10:32:59.107766Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                filepath  label       breed\n0      /kaggle/input/nhapmoncv/data/images/n02091635-...      0  otterhound\n1      /kaggle/input/nhapmoncv/data/images/n02091635-...      0  otterhound\n2      /kaggle/input/nhapmoncv/data/images/n02091635-...      0  otterhound\n3      /kaggle/input/nhapmoncv/data/images/n02091635-...      0  otterhound\n4      /kaggle/input/nhapmoncv/data/images/n02091635-...      0  otterhound\n...                                                  ...    ...         ...\n20575  /kaggle/input/nhapmoncv/data/images/n02088466-...    119  bloodhound\n20576  /kaggle/input/nhapmoncv/data/images/n02088466-...    119  bloodhound\n20577  /kaggle/input/nhapmoncv/data/images/n02088466-...    119  bloodhound\n20578  /kaggle/input/nhapmoncv/data/images/n02088466-...    119  bloodhound\n20579  /kaggle/input/nhapmoncv/data/images/n02088466-...    119  bloodhound\n\n[20580 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n      <th>label</th>\n      <th>breed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/nhapmoncv/data/images/n02091635-...</td>\n      <td>0</td>\n      <td>otterhound</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/nhapmoncv/data/images/n02091635-...</td>\n      <td>0</td>\n      <td>otterhound</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/nhapmoncv/data/images/n02091635-...</td>\n      <td>0</td>\n      <td>otterhound</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/nhapmoncv/data/images/n02091635-...</td>\n      <td>0</td>\n      <td>otterhound</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/nhapmoncv/data/images/n02091635-...</td>\n      <td>0</td>\n      <td>otterhound</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20575</th>\n      <td>/kaggle/input/nhapmoncv/data/images/n02088466-...</td>\n      <td>119</td>\n      <td>bloodhound</td>\n    </tr>\n    <tr>\n      <th>20576</th>\n      <td>/kaggle/input/nhapmoncv/data/images/n02088466-...</td>\n      <td>119</td>\n      <td>bloodhound</td>\n    </tr>\n    <tr>\n      <th>20577</th>\n      <td>/kaggle/input/nhapmoncv/data/images/n02088466-...</td>\n      <td>119</td>\n      <td>bloodhound</td>\n    </tr>\n    <tr>\n      <th>20578</th>\n      <td>/kaggle/input/nhapmoncv/data/images/n02088466-...</td>\n      <td>119</td>\n      <td>bloodhound</td>\n    </tr>\n    <tr>\n      <th>20579</th>\n      <td>/kaggle/input/nhapmoncv/data/images/n02088466-...</td>\n      <td>119</td>\n      <td>bloodhound</td>\n    </tr>\n  </tbody>\n</table>\n<p>20580 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"id":"b5db6360","cell_type":"markdown","source":"# COLOR HISTOGRAM","metadata":{}},{"id":"ba7ce7d5","cell_type":"code","source":"def color_feature_extractor(img):\n    hist_r = cv2.calcHist([img], [0], None, [16], [0, 256])\n    hist_g = cv2.calcHist([img], [1], None, [16], [0, 256])\n    hist_b = cv2.calcHist([img], [2], None, [16], [0, 256])\n\n    feature_vector = np.concatenate([hist_r, hist_g, hist_b]).flatten()\n\n    feature_vector = feature_vector / np.sum(feature_vector)\n    return feature_vector\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:32:59.109556Z","iopub.execute_input":"2025-10-21T10:32:59.109845Z","iopub.status.idle":"2025-10-21T10:32:59.116332Z","shell.execute_reply.started":"2025-10-21T10:32:59.109819Z","shell.execute_reply":"2025-10-21T10:32:59.115378Z"}},"outputs":[],"execution_count":7},{"id":"11e2118a","cell_type":"code","source":"color_feature_vectors = []\n\nfor _, row in df.iterrows():\n    color_feature_vectors.append(color_feature_extractor(cv2.imread(row[\"filepath\"])))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:32:59.117232Z","iopub.execute_input":"2025-10-21T10:32:59.117750Z","iopub.status.idle":"2025-10-21T10:36:27.690799Z","shell.execute_reply.started":"2025-10-21T10:32:59.117727Z","shell.execute_reply":"2025-10-21T10:36:27.689918Z"}},"outputs":[],"execution_count":8},{"id":"afbb40c2","cell_type":"code","source":"x = np.array(color_feature_vectors)\ny = np.array(list(df[\"label\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:36:27.691760Z","iopub.execute_input":"2025-10-21T10:36:27.692002Z","iopub.status.idle":"2025-10-21T10:36:27.712246Z","shell.execute_reply.started":"2025-10-21T10:36:27.691983Z","shell.execute_reply":"2025-10-21T10:36:27.711518Z"}},"outputs":[],"execution_count":9},{"id":"dbf1c7f1","cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:36:27.713060Z","iopub.execute_input":"2025-10-21T10:36:27.713320Z","iopub.status.idle":"2025-10-21T10:36:27.721463Z","shell.execute_reply.started":"2025-10-21T10:36:27.713294Z","shell.execute_reply":"2025-10-21T10:36:27.720550Z"}},"outputs":[],"execution_count":10},{"id":"4871efab","cell_type":"code","source":"rf = RandomForestClassifier()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:36:27.724091Z","iopub.execute_input":"2025-10-21T10:36:27.724441Z","iopub.status.idle":"2025-10-21T10:36:27.732253Z","shell.execute_reply.started":"2025-10-21T10:36:27.724414Z","shell.execute_reply":"2025-10-21T10:36:27.731354Z"}},"outputs":[],"execution_count":11},{"id":"c30190fc","cell_type":"code","source":"rf.fit(x_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:36:27.733166Z","iopub.execute_input":"2025-10-21T10:36:27.733529Z","iopub.status.idle":"2025-10-21T10:37:32.759781Z","shell.execute_reply.started":"2025-10-21T10:36:27.733506Z","shell.execute_reply":"2025-10-21T10:37:32.758872Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":12},{"id":"23fa1663","cell_type":"code","source":"y_pred = rf.predict(x_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred) * 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:37:32.760691Z","iopub.execute_input":"2025-10-21T10:37:32.760903Z","iopub.status.idle":"2025-10-21T10:37:33.136079Z","shell.execute_reply.started":"2025-10-21T10:37:32.760886Z","shell.execute_reply":"2025-10-21T10:37:33.135227Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 6.365403304178814\n","output_type":"stream"}],"execution_count":13},{"id":"eaa30e9a","cell_type":"markdown","source":"# HOG","metadata":{}},{"id":"74fd9819","cell_type":"code","source":"def compute_hog(img_path, target_size=(128, 128)):\n    try:\n        img = io.imread(img_path)\n        img = resize(img, target_size)\n        img_gray = color.rgb2gray(img)\n\n        features = hog(\n            img_gray,\n            orientations=8,\n            pixels_per_cell=(8, 8),\n            cells_per_block=(2, 2),\n            block_norm='L2-Hys',\n            visualize=False,       \n            feature_vector=True\n        )\n        return features\n    except Exception as err:\n        print(f\"[WARN] Skipped {img_path}: {err}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T13:20:34.099784Z","iopub.execute_input":"2025-10-21T13:20:34.101096Z","iopub.status.idle":"2025-10-21T13:20:34.107692Z","shell.execute_reply.started":"2025-10-21T13:20:34.101052Z","shell.execute_reply":"2025-10-21T13:20:34.106354Z"}},"outputs":[],"execution_count":28},{"id":"a8396cd3-c601-4362-af9f-95ec09297eb1","cell_type":"code","source":"features_list = Parallel(n_jobs=-1, backend='loky')(\n    delayed(compute_hog)(p) for p in df[\"filepath\"]\n)\n\n\nvalid_mask = [f is not None for f in features_list]\n\nX = np.vstack([f for f in features_list if f is not None])\ny = df.loc[valid_mask, \"label\"].values\n\nprint(f\"âœ… Features extracted for {len(X)} of {len(df)} images\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T13:57:04.572323Z","iopub.execute_input":"2025-10-21T13:57:04.572783Z","iopub.status.idle":"2025-10-21T14:02:09.183040Z","shell.execute_reply.started":"2025-10-21T13:57:04.572755Z","shell.execute_reply":"2025-10-21T14:02:09.181792Z"}},"outputs":[{"name":"stdout","text":"âœ… Features extracted for 20579 of 20580 images\n","output_type":"stream"}],"execution_count":36},{"id":"66aedef6","cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\nrf = RandomForestClassifier()\nrf.fit(x_train, y_train)\ny_pred = rf.predict(x_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred) * 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T14:02:09.185191Z","iopub.execute_input":"2025-10-21T14:02:09.185509Z","iopub.status.idle":"2025-10-21T14:52:59.206166Z","shell.execute_reply.started":"2025-10-21T14:02:09.185483Z","shell.execute_reply":"2025-10-21T14:52:59.201970Z"}},"outputs":[{"name":"stdout","text":"[WARN] Skipped /kaggle/input/nhapmoncv/data/images/n02105855-Shetland_sheepdog/n02105855_2933.jpg: the input array must have size 3 along `channel_axis`, got (128, 128, 4)\nAccuracy: 3.1098153547133136\n","output_type":"stream"}],"execution_count":37},{"id":"1ddd997f","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e57d505b-b056-4c87-a2a9-ab1f184ccc2c","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}