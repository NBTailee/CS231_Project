{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13452811,"sourceType":"datasetVersion","datasetId":8539258}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport seaborn as sns\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom skimage import io, color\nfrom skimage.feature import local_binary_pattern\nfrom joblib import Parallel, delayed\nfrom skimage.transform import resize\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:05:26.179850Z","iopub.execute_input":"2025-10-23T16:05:26.180220Z","iopub.status.idle":"2025-10-23T16:05:26.184964Z","shell.execute_reply.started":"2025-10-23T16:05:26.180189Z","shell.execute_reply":"2025-10-23T16:05:26.184196Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"images_dir = '/kaggle/input/nhapmoncv/data/images'\nclasses = [d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))]\n\nlabel_map = {cls: idx for idx, cls in enumerate(classes)}\n\ndata = []\nfor cls in classes:\n    cls_folder = os.path.join(images_dir, cls)\n    for fname in os.listdir(cls_folder):\n        if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n            file_path = os.path.join(cls_folder, fname)\n            label = label_map[cls]\n            data.append((file_path, label))\n\n\nclasses = [d.split(\"-\")[-1] for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))]\nlabel_map = {cls: idx for idx, cls in enumerate(classes)}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:05:26.186132Z","iopub.execute_input":"2025-10-23T16:05:26.186365Z","iopub.status.idle":"2025-10-23T16:05:26.543219Z","shell.execute_reply.started":"2025-10-23T16:05:26.186346Z","shell.execute_reply":"2025-10-23T16:05:26.542608Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"df = pd.DataFrame(data, columns=['filepath', 'label'])\nprint(df.head())\nprint(\"Number of images:\", len(df))\nprint(\"Number of classes:\", len(classes))\n\nlabel_map = {v: k for k, v in label_map.items()}\ndf[\"breed\"] = df[\"label\"].map(label_map)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:05:26.543955Z","iopub.execute_input":"2025-10-23T16:05:26.544228Z","iopub.status.idle":"2025-10-23T16:05:26.558897Z","shell.execute_reply.started":"2025-10-23T16:05:26.544203Z","shell.execute_reply":"2025-10-23T16:05:26.558098Z"}},"outputs":[{"name":"stdout","text":"                                            filepath  label\n0  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\n1  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\n2  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\n3  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\n4  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\nNumber of images: 20580\nNumber of classes: 120\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"print(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:05:26.560546Z","iopub.execute_input":"2025-10-23T16:05:26.560774Z","iopub.status.idle":"2025-10-23T16:05:26.575350Z","shell.execute_reply.started":"2025-10-23T16:05:26.560733Z","shell.execute_reply":"2025-10-23T16:05:26.574789Z"}},"outputs":[{"name":"stdout","text":"                                            filepath  label       breed\n0  /kaggle/input/nhapmoncv/data/images/n02091635-...      0  otterhound\n1  /kaggle/input/nhapmoncv/data/images/n02091635-...      0  otterhound\n2  /kaggle/input/nhapmoncv/data/images/n02091635-...      0  otterhound\n3  /kaggle/input/nhapmoncv/data/images/n02091635-...      0  otterhound\n4  /kaggle/input/nhapmoncv/data/images/n02091635-...      0  otterhound\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def compute_lbp(img_path, target_size=(128, 128), P=8, R=1):\n        img = io.imread(img_path)\n        img = resize(img, target_size)\n        if img.shape[-1] == 4:\n            img = img[:, :, :3]\n\n        img_gray = (color.rgb2gray(img) * 255).astype('uint8')\n\n        lbp = local_binary_pattern(img_gray, P=P, R=R, method='uniform')\n\n        n_bins = int(lbp.max() + 1)\n        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n\n        return hist","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:05:26.576181Z","iopub.execute_input":"2025-10-23T16:05:26.576621Z","iopub.status.idle":"2025-10-23T16:05:26.590313Z","shell.execute_reply.started":"2025-10-23T16:05:26.576603Z","shell.execute_reply":"2025-10-23T16:05:26.589561Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"features_list = Parallel(n_jobs=-1, backend='loky')(\n    delayed(compute_lbp)(p) for p in df[\"filepath\"]\n)\n\nvalid_mask = [f is not None for f in features_list]\nX = np.vstack([f for f in features_list if f is not None])\ny = df.loc[valid_mask, \"label\"].values\n\nprint(f\"LBP features extracted for {len(X)} of {len(df)} images\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:05:26.590883Z","iopub.execute_input":"2025-10-23T16:05:26.591059Z","iopub.status.idle":"2025-10-23T16:08:56.442088Z","shell.execute_reply.started":"2025-10-23T16:05:26.591046Z","shell.execute_reply":"2025-10-23T16:08:56.441256Z"}},"outputs":[{"name":"stdout","text":"LBP features extracted for 20580 of 20580 images\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nrf = RandomForestClassifier()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:08:56.442998Z","iopub.execute_input":"2025-10-23T16:08:56.443376Z","iopub.status.idle":"2025-10-23T16:08:56.449906Z","shell.execute_reply.started":"2025-10-23T16:08:56.443343Z","shell.execute_reply":"2025-10-23T16:08:56.449249Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"rf.fit(x_train, y_train)\ny_pred = rf.predict(x_test)\n\nprint(\"Accuracy (LBP):\", accuracy_score(y_test, y_pred) * 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:08:56.450920Z","iopub.execute_input":"2025-10-23T16:08:56.451206Z","iopub.status.idle":"2025-10-23T16:09:17.144036Z","shell.execute_reply.started":"2025-10-23T16:08:56.451183Z","shell.execute_reply":"2025-10-23T16:09:17.142981Z"}},"outputs":[{"name":"stdout","text":"Accuracy (LBP): 3.231292517006803\n","output_type":"stream"}],"execution_count":28}]}