{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13452811,"sourceType":"datasetVersion","datasetId":8539258}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U huggingface_hub transformers==4.44.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:50:46.198323Z","iopub.execute_input":"2025-10-22T07:50:46.199033Z","iopub.status.idle":"2025-10-22T07:50:59.684358Z","shell.execute_reply.started":"2025-10-22T07:50:46.199005Z","shell.execute_reply":"2025-10-22T07:50:59.683412Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (1.0.0rc2)\nCollecting transformers==4.44.2\n  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (3.19.1)\nCollecting huggingface_hub\n  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2.32.5)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.5.3)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2025.8.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.44.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface_hub, tokenizers, transformers\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface_hub-0.35.3 tokenizers-0.19.1 transformers-4.44.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:50:59.685956Z","iopub.execute_input":"2025-10-22T07:50:59.686214Z","iopub.status.idle":"2025-10-22T07:51:00.148756Z","shell.execute_reply.started":"2025-10-22T07:50:59.686191Z","shell.execute_reply":"2025-10-22T07:51:00.148188Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport seaborn as sns\nimport cv2\nimport numpy as np \nfrom PIL import Image\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom skimage import io, color\nfrom skimage.feature import hog\nfrom joblib import Parallel, delayed\nimport numpy as np\nfrom skimage.transform import resize\nfrom transformers import CLIPProcessor, CLIPModel, AutoModelForZeroShotImageClassification, AutoProcessor\nfrom tqdm import tqdm\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:56:53.870490Z","iopub.execute_input":"2025-10-22T07:56:53.870781Z","iopub.status.idle":"2025-10-22T07:56:53.875858Z","shell.execute_reply.started":"2025-10-22T07:56:53.870762Z","shell.execute_reply":"2025-10-22T07:56:53.875125Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\n\nimages_dir = '/kaggle/input/nhapmoncv/data/images'\n\nclasses = [d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))]\n\nlabel_map = {cls: idx for idx, cls in enumerate(classes)}\n\ndata = []\nfor cls in classes:\n    cls_folder = os.path.join(images_dir, cls)\n    for fname in os.listdir(cls_folder):\n        if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n            file_path = os.path.join(cls_folder, fname)\n            label = label_map[cls]\n            data.append((file_path, label))\n\nclasses = [d.split(\"-\")[-1] for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))]\n\nlabel_map = {cls: idx for idx, cls in enumerate(classes)}\n\n\ndf = pd.DataFrame(data, columns=['filepath', 'label'])\nprint(df.head())\nprint(\"Number of images:\", len(df))\nprint(\"Number of classes:\", len(classes))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:51:21.442018Z","iopub.execute_input":"2025-10-22T07:51:21.442614Z","iopub.status.idle":"2025-10-22T07:51:23.089494Z","shell.execute_reply.started":"2025-10-22T07:51:21.442595Z","shell.execute_reply":"2025-10-22T07:51:23.088690Z"}},"outputs":[{"name":"stdout","text":"                                            filepath  label\n0  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\n1  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\n2  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\n3  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\n4  /kaggle/input/nhapmoncv/data/images/n02091635-...      0\nNumber of images: 20580\nNumber of classes: 120\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"label_map = {v:k for k,v in label_map.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:51:23.090271Z","iopub.execute_input":"2025-10-22T07:51:23.090524Z","iopub.status.idle":"2025-10-22T07:51:23.094224Z","shell.execute_reply.started":"2025-10-22T07:51:23.090495Z","shell.execute_reply":"2025-10-22T07:51:23.093519Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df[\"breed\"] = df[\"label\"].map(label_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:51:23.095071Z","iopub.execute_input":"2025-10-22T07:51:23.095323Z","iopub.status.idle":"2025-10-22T07:51:23.114188Z","shell.execute_reply.started":"2025-10-22T07:51:23.095306Z","shell.execute_reply":"2025-10-22T07:51:23.113454Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model_name = \"laion/CLIP-ViT-L-14-laion2B-s32B-b82K\"\nmodel = AutoModelForZeroShotImageClassification.from_pretrained(model_name)\nprocessor = CLIPProcessor.from_pretrained(model_name)\n\nmodel.eval().to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:51:23.114939Z","iopub.execute_input":"2025-10-22T07:51:23.115225Z","iopub.status.idle":"2025-10-22T07:51:33.168591Z","shell.execute_reply.started":"2025-10-22T07:51:23.115199Z","shell.execute_reply":"2025-10-22T07:51:33.167754Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66781d1cb54a4eb5a770d6005d6def06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80e6bda19745458ca5c1bde631bc2478"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/275 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5d9f16916534085a651337385f5a5a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/904 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40eeaf2e3342463580989cac4395c2ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c1266282df6406ca1c09f233f53a9e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c67031b8b3ee4e8dbcb945e606482e1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12551d9603dc491aa2966ec444eb80a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b6e53abc85d47359bf3d7c035e39cac"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"CLIPModel(\n  (text_model): CLIPTextTransformer(\n    (embeddings): CLIPTextEmbeddings(\n      (token_embedding): Embedding(49408, 768)\n      (position_embedding): Embedding(77, 768)\n    )\n    (encoder): CLIPEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x CLIPEncoderLayer(\n          (self_attn): CLIPSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): CLIPMLP(\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (vision_model): CLIPVisionTransformer(\n    (embeddings): CLIPVisionEmbeddings(\n      (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n      (position_embedding): Embedding(257, 1024)\n    )\n    (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    (encoder): CLIPEncoder(\n      (layers): ModuleList(\n        (0-23): 24 x CLIPEncoderLayer(\n          (self_attn): CLIPSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (mlp): CLIPMLP(\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          )\n          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n  )\n  (visual_projection): Linear(in_features=1024, out_features=768, bias=False)\n  (text_projection): Linear(in_features=768, out_features=768, bias=False)\n)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"embeddings = []\n\nfor path in tqdm(df[\"filepath\"]):\n    image = Image.open(path).convert(\"RGB\")\n    inputs = processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n    with torch.no_grad():\n        img_features = model.get_image_features(**inputs)\n    embeddings.append(img_features.cpu().numpy().flatten())\n\nX = np.vstack(embeddings)\ny = df[\"label\"].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T07:56:57.272229Z","iopub.execute_input":"2025-10-22T07:56:57.272504Z","iopub.status.idle":"2025-10-22T08:15:46.901602Z","shell.execute_reply.started":"2025-10-22T07:56:57.272485Z","shell.execute_reply":"2025-10-22T08:15:46.900830Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 20580/20580 [18:49<00:00, 18.22it/s]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nrf = RandomForestClassifier(\n    random_state=42\n)\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T08:24:42.864317Z","iopub.execute_input":"2025-10-22T08:24:42.864809Z","iopub.status.idle":"2025-10-22T08:27:00.581137Z","shell.execute_reply.started":"2025-10-22T08:24:42.864786Z","shell.execute_reply":"2025-10-22T08:27:00.580415Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.7402818270165209\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}